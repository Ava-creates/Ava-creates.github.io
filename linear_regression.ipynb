{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ava-creates/Ava-creates.github.io/blob/main/linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    
    {
      "cell_type": "markdown",
      "source": [
        "#Explore and import Boston house prices dataset"
      ],
      "metadata": {
        "id": "ObVU6llW-X8l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-hieMV8Obn6",
        "outputId": "eb3552fe-c193-49c0-ec58-4230a87d683f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(506,)\n"
          ]
        }
      ],
      "source": [
        "#importing campus\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_boston\n",
        "with warnings.catch_warnings():\n",
        "# You should probably not use this dataset. LOVE THE WARNING\n",
        "  warnings.filterwarnings(\"ignore\")\n",
        "  X, y = load_boston(return_X_y=True)\n",
        "\n",
        "#df = pd.DataFrame(X)\n",
        "\n",
        "print(y.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y.reshape((253,2))\n",
        "\n",
        "\n",
        "#no idea why we are doing this tho\n"
      ],
      "metadata": {
        "id": "ODN_QlMpYdie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "o=np.ones(X.shape[0])\n",
        "X= np.insert(X, 0, o, axis=1)\n",
        "print(X)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "7LJPSK5wbi4m",
        "outputId": "695b9ff9-44bb-4ec4-8edc-9f677aef4060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\no=np.ones(X.shape[0])\\nX= np.insert(X, 0, o, axis=1)\\nprint(X)\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#getting w wihtout ridge"
      ],
      "metadata": {
        "id": "Pn8V50Ju-jF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weight(X, y ):\n",
        "  #w=inv(xt x)xt y\n",
        "  XT=np.transpose(X)\n",
        "  w= np.array((np.linalg.inv(XT@X)) @ XT @y)\n",
        "#linalg.inv(a)\n",
        "  #print(w)\n",
        "  return w\n",
        "\n",
        "w=get_weight(X,y)\n",
        "w.shape"
      ],
      "metadata": {
        "id": "2z35EP_sb7F2",
        "outputId": "36eb47ea-202d-4959-a08a-e24a8fc916f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13,)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#getting w with ridge"
      ],
      "metadata": {
        "id": "XBzN26yX-sRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weightridge(X, y , alpha):\n",
        "  #w=inv(xt x)xt y\n",
        "  XT=np.transpose(X)\n",
        "  I= np.identity(X.shape[1], dtype=\"int\")\n",
        "  w= (np.linalg.inv((XT@X)+alpha*I)) @ XT @y\n",
        "#linalg.inv(a)\n",
        "  #print(w)\n",
        "  #w[0] =  np.mean(y)\n",
        "  #print(w)\n",
        "  return w\n",
        "\n",
        "get_weightridge(X,y, .001)"
      ],
      "metadata": {
        "id": "xSooWgZRceMk",
        "outputId": "201ff4cf-3bfc-46b3-8358-f2932c429b10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-9.28962007e-02,  4.87153511e-02, -4.06707120e-03,  2.85388960e+00,\n",
              "       -2.86698669e+00,  5.92806695e+00, -7.27042723e-03, -9.68501856e-01,\n",
              "        1.71151992e-01, -9.39650991e-03, -3.92188246e-01,  1.49055445e-02,\n",
              "       -4.16312330e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#hypothesis actual prediction happening"
      ],
      "metadata": {
        "id": "5_ia0zy1-uos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hypothesis(X, w):\n",
        "  \n",
        "  \n",
        "  h=w@np.transpose(X) # h(w) \n",
        "\n",
        "  #print(h)\n",
        "  #print(h.shape)\n",
        " # h=np.sum(h)\n",
        "  return h\n",
        "\n",
        "#hypothesis(X,w) #"
      ],
      "metadata": {
        "id": "Lni_ZNnthEVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#cost/loss function"
      ],
      "metadata": {
        "id": "TY1xFuFw-yQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_error(X_train, y_train, X_test, y_test, alpha):\n",
        "  predict_train= hypothesis(X_train, get_weightridge(X_train, y_train, alpha ))  + np.mean(y_train)\n",
        "  predict_test=hypothesis(X_test, get_weightridge(X_test, y_test, alpha)) + np.mean(y_train)\n",
        "\n",
        "  t=(y_train-predict_train)**2\n",
        "  \n",
        "  train_err=np.mean(t)\n",
        "  test_err=np.mean((y_test-predict_test)**2)\n",
        "\n",
        "  #print(train_err)\n",
        "  #print(test_err)\n",
        "  \n",
        "  return (train_err, test_err)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "jq6bk8NsdidK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#k-folding and then doing the thing for all the 10 folds"
      ],
      "metadata": {
        "id": "A9csxv4z-6DV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "def k_fold_regression(k, X, y, alpha):\n",
        "  kf=KFold(n_splits=k, random_state=21, shuffle=True )\n",
        "\n",
        "  d=0\n",
        "  c=0\n",
        "  a=[]\n",
        "  for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test=X[train_index], X[test_index]\n",
        "    y_train, y_test=y[train_index], y[test_index]\n",
        "    \n",
        "    #centering data to avoid getting b\n",
        "    \n",
        "    y_mean=np.mean(y_train)\n",
        "    y_train-=y_mean\n",
        "    y_test-=y_mean\n",
        "    #scaling??\n",
        "\n",
        "    #scaler= preproccessing_StandardScaler().fit()\n",
        "    from sklearn import preprocessing \n",
        "    scaler_train = preprocessing.StandardScaler().fit(X_train)\n",
        "    scaler_test = preprocessing.StandardScaler().fit(X_test)\n",
        "    X_train_scaled = scaler_train.transform(X_train)\n",
        "    X_test_scaled= scaler_test.transform(X_test)  \n",
        "    a.append(eval_error(X_train_scaled, y_train, X_test_scaled, y_test, alpha))\n",
        "   # print(eval_error(X_train_scaled, y_train, X_test_scaled, y_test, alpha))\n",
        "  test_mean=0\n",
        "  train_mean=0\n",
        "  for i in a:\n",
        "    test_mean+=i[1]\n",
        "    train_mean+=i[0]\n",
        "\n",
        "  return (train_mean/k, test_mean/k)\n",
        "\n",
        "\n",
        "\n",
        "#k_fold_regression(10, X, y, .0001)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "KhLBu7UKxW7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#finding the best alpha"
      ],
      "metadata": {
        "id": "7XlY22mT_Ce8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###trying linear regression with no ridge is better than ridge 10###\n",
        "a,b=k_fold_regression(10, X, y, 0)\n",
        "print(\"--------------------------------------\")\n",
        "print(\"train: \", a ,\"\\t\", \"test:\", b )\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcXU76EuXJT0",
        "outputId": "c38bc64e-5568-493a-8522-404a21f92c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------\n",
            "train:  21.806183575851065 \t test: 16.460424621999827\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = np.logspace(1, 7, num=13) \n"
      ],
      "metadata": {
        "id": "fNmcoj7jWOH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in n:\n",
        "  print(i)\n",
        "  a,b=k_fold_regression(10, X, y, i)\n",
        "  print(\"--------------------------------------\")\n",
        "  print(\"train: \", a ,\"\\t\", \"test:\", b )\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "#10 is the best fit as it has the lowest error\n"
      ],
      "metadata": {
        "id": "pJcCaFESWIG8",
        "outputId": "dd542c46-0ff4-42d0-cf52-50ab0023785e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.0\n",
            "--------------------------------------\n",
            "train:  21.892901157570186 \t test: 18.871365859469368\n",
            "\n",
            "\n",
            "31.622776601683793\n",
            "--------------------------------------\n",
            "train:  22.285444055697496 \t test: 23.667676104913077\n",
            "\n",
            "\n",
            "100.0\n",
            "--------------------------------------\n",
            "train:  23.725488384882073 \t test: 34.29926125871303\n",
            "\n",
            "\n",
            "316.22776601683796\n",
            "--------------------------------------\n",
            "train:  28.166554098540104 \t test: 50.55992463602915\n",
            "\n",
            "\n",
            "1000.0\n",
            "--------------------------------------\n",
            "train:  38.53214872734354 \t test: 67.2339588178375\n",
            "\n",
            "\n",
            "3162.2776601683795\n",
            "--------------------------------------\n",
            "train:  54.007026499554456 \t test: 77.82893450066003\n",
            "\n",
            "\n",
            "10000.0\n",
            "--------------------------------------\n",
            "train:  69.25978171325319 \t test: 82.38050719533354\n",
            "\n",
            "\n",
            "31622.776601683792\n",
            "--------------------------------------\n",
            "train:  78.53074243629268 \t test: 83.9881811181876\n",
            "\n",
            "\n",
            "100000.0\n",
            "--------------------------------------\n",
            "train:  82.40325012491365 \t test: 84.51553966791388\n",
            "\n",
            "\n",
            "316227.7660168379\n",
            "--------------------------------------\n",
            "train:  83.75514887733652 \t test: 84.68427773579137\n",
            "\n",
            "\n",
            "1000000.0\n",
            "--------------------------------------\n",
            "train:  84.19680334862028 \t test: 84.7378371584751\n",
            "\n",
            "\n",
            "3162277.6601683795\n",
            "--------------------------------------\n",
            "train:  84.33793107733854 \t test: 84.75479419099426\n",
            "\n",
            "\n",
            "10000000.0\n",
            "--------------------------------------\n",
            "train:  84.38270764054002 \t test: 84.76015848363588\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#adding polynomial feature to the data better result for degree 2"
      ],
      "metadata": {
        "id": "6farL5_w_IIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly=PolynomialFeatures(2)\n",
        "X_poly=poly.fit_transform(X)\n",
        "\n",
        "for i in n:\n",
        "  print(i)\n",
        "  a,b=k_fold_regression(10, X_poly, y, i)\n",
        "  print(\"--------------------------------------\")\n",
        "  print(\"train: \", a ,\"\\t\", \"test:\", b )\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "#polynomial feature is better\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "XWZlLXGuywVn",
        "outputId": "d59d3bd4-1496-4515-db03-a9c7152ceb54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.0\n",
            "--------------------------------------\n",
            "train:  10.049055874118874 \t test: 9.885809229746553\n",
            "\n",
            "\n",
            "31.622776601683793\n",
            "--------------------------------------\n",
            "train:  12.751706269046785 \t test: 13.325586401894473\n",
            "\n",
            "\n",
            "100.0\n",
            "--------------------------------------\n",
            "train:  16.2226905932108 \t test: 18.271071274361038\n",
            "\n",
            "\n",
            "316.22776601683796\n",
            "--------------------------------------\n",
            "train:  19.700253646409855 \t test: 27.2851822711348\n",
            "\n",
            "\n",
            "1000.0\n",
            "--------------------------------------\n",
            "train:  24.287457983108876 \t test: 41.5810366942791\n",
            "\n",
            "\n",
            "3162.2776601683795\n",
            "--------------------------------------\n",
            "train:  33.086668319850524 \t test: 58.34878157435058\n",
            "\n",
            "\n",
            "10000.0\n",
            "--------------------------------------\n",
            "train:  46.76199935941408 \t test: 72.47260047971982\n",
            "\n",
            "\n",
            "31622.776601683792\n",
            "--------------------------------------\n",
            "train:  62.00900191683604 \t test: 80.17338052568638\n",
            "\n",
            "\n",
            "100000.0\n",
            "--------------------------------------\n",
            "train:  74.28758894586744 \t test: 83.2228109176057\n",
            "\n",
            "\n",
            "316227.7660168379\n",
            "--------------------------------------\n",
            "train:  80.69255135236737 \t test: 84.26610689712982\n",
            "\n",
            "\n",
            "1000000.0\n",
            "--------------------------------------\n",
            "train:  83.16723569778432 \t test: 84.60463721235524\n",
            "\n",
            "\n",
            "3162277.6601683795\n",
            "--------------------------------------\n",
            "train:  84.00579580096273 \t test: 84.71257557567883\n",
            "\n",
            "\n",
            "10000000.0\n",
            "--------------------------------------\n",
            "train:  84.2770062647736 \t test: 84.74679804960701\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#the end \n",
        "\n",
        "\n",
        "*  alpha 10 gives the best result\n",
        "*  polynomisal feature of degree 2 gives better result\n",
        "\n"
      ],
      "metadata": {
        "id": "nI55igpeYpzs"
      }
    }
  ]
}
